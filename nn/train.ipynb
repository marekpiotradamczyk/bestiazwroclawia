{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T17:25:19.453256Z",
     "start_time": "2024-05-04T17:25:19.449983Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import gc\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import ceil\n",
    "from tqdm.notebook import tqdm\n",
    "from copy import deepcopy \n",
    "from tabulate import tabulate\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from collections import namedtuple\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe9d0fda-f33e-4313-850b-f3b640d2c201",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Basic structure\n",
    "\n",
    "DATA_DIR = \"data/\"\n",
    "STOCKFISH_DIR = 'stockfish/'\n",
    "ARCHIVE_DIR = DATA_DIR + 'archives/'\n",
    "\n",
    "###\n",
    "##\n",
    "###\n",
    "\n",
    "### Stockfish\n",
    "\n",
    "STOCKFISH_AVX512_TAR = \"stockfish-ubuntu-x86-64-avx512.tar\"\n",
    "STOCKFISH_AVX512 = \"stockfish-ubuntu-x86-64-avx512\"\n",
    "STOCKFISH_AVX512_EXE = STOCKFISH_DIR + STOCKFISH_AVX512\n",
    "\n",
    "\n",
    "###\n",
    "##\n",
    "###\n",
    "\n",
    "### URLs\n",
    "\n",
    "ELITE_DATABASE_URL  = \"https://database.nikonoel.fr/lichess_elite_2021-11.zip\"\n",
    "STOCKFISH_DOWNSTREAM = \"https://github.com/official-stockfish/Stockfish/releases/latest/download/\"\n",
    "STOCKFISH_AVX512_URL = STOCKFISH_DOWNSTREAM + STOCKFISH_AVX512_TAR\n",
    "\n",
    "### \n",
    "##\n",
    "###\n",
    "\n",
    "### Datasets \n",
    "\n",
    "ELITE_DATASET_ARCHIVE = \"lichess_elite_2021-11.zip\"\n",
    "ELITE_DATASET_FILENAME = \"lichess_elite_2021-11.pgn\"\n",
    "\n",
    "\n",
    "LICHESS_EVAL_ARCHIVE = ARCHIVE_DIR + \"lichess_db_eval.jsonl.zst\"\n",
    "LICHESS_EVAL_FILENAME = DATA_DIR + \"lichess_db_eval.jsonl\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b13750a6be5e8a69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T14:57:01.510501Z",
     "start_time": "2024-05-03T14:57:01.178672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BITBOARD_DIR = DATA_DIR + 'bitboards/'\n",
    "ELITE_DATA_BASE_URL  = \"https://database.nikonoel.fr/\"\n",
    "STOCKFISH_DOWNSTREAM = \"https://github.com/official-stockfish/Stockfish/releases/latest/download/\"\n",
    "\n",
    "SAMPLE_ZIP = \"lichess_elite_2021-11.zip\"\n",
    "SAMPLE_PGN = \"lichess_elite_2021-11.pgn\"\n",
    "SAMPLE_BITBOARD = \"elite_bitboard.csv\"\n",
    "BITBOARD_1M = \"1M.csv\"\n",
    "BITBOARD_10M = \"10M.csv\"\n",
    "ELITE_DATA_SAMPLE_URL = ELITE_DATA_BASE_URL + SAMPLE_ZIP\n",
    "SAMPLE_ZIP_FILE = ARCHIVE_DIR + SAMPLE_ZIP\n",
    "SAMPLE_PGN_FILE  = DATA_DIR + SAMPLE_PGN\n",
    "\n",
    "SAMPLE_BITBOARD_FILE = BITBOARD_DIR + SAMPLE_BITBOARD\n",
    "BITBOARD_10M_FILE = BITBOARD_DIR + BITBOARD_10M\n",
    "BITBOARD_1M_FILE = BITBOARD_DIR + BITBOARD_1M\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edce589a-5035-4fc0-96c1-3375d53daa5f",
   "metadata": {},
   "source": [
    "# Dataset and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "91dc98ff-9857-4ec6-9c98-9550feba6472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated: 52M\n",
      "Reserved: 67M\n"
     ]
    }
   ],
   "source": [
    "# def sizeof_fmt(num, suffix=\"B\"):\n",
    "#     for unit in (\"\", \"Ki\", \"Mi\", \"Gi\"):\n",
    "#         if abs(num) < 1024.0:\n",
    "#             return f\"{num:3.1f}{unit}{suffix}\"\n",
    "#         num /= 1024.0\n",
    "#     return f\"{num:.1f}Yi{suffix}\"\n",
    "    \n",
    "def sizeof_fmt(num):\n",
    "    for unit in (\"\", \"K\", \"M\", \"G\"):\n",
    "        if abs(num) < 1000.0:\n",
    "            return f\"{num:.0f}{unit}\"\n",
    "        num /= 1000.0\n",
    "    return f\"{num:.0f}\"\n",
    "\n",
    "\n",
    "print(f\"Allocated: {sizeof_fmt(torch.cuda.memory_allocated())}\") \n",
    "print(f\"Reserved: {sizeof_fmt(torch.cuda.memory_reserved())}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "608b0930c754cabd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-03T14:57:06.739621Z",
     "start_time": "2024-05-03T14:57:06.735393Z"
    }
   },
   "outputs": [],
   "source": [
    "class BitboardDrawDatasetSimple(Dataset):\n",
    "    def __init__(self, bitboard_file):\n",
    "        bitboards_df = pd.read_csv(bitboard_file, sep=\";\", dtype=\"uint64\", usecols=range(12))\n",
    "        metadata_df = pd.read_csv(bitboard_file, sep=\";\")\n",
    "\n",
    "        self.bitboards = self.bitboards_to_layers(bitboards_df)\n",
    "        # self.meta_features = self.binary_features_to_layers(metadata_df[[\"white\", \"cK\", \"cQ\", \"ck\", \"cq\"]])\n",
    "        self.is_draw = metadata_df['draw'].to_numpy(dtype=np.single)\n",
    "        self.length = self.is_draw.size\n",
    "\n",
    "        # self.bitboards = np.hstack((self.bitboards, self.meta_features))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.bitboards[idx], self.is_draw[idx]\n",
    "\n",
    "    def bitboards_to_layers(self, bitboards):\n",
    "        return np.unpackbits(np.ascontiguousarray(bitboards.to_numpy()).view(np.uint8), axis=1).astype(np.single)\n",
    "\n",
    "    def binary_features_to_layers(self, features):\n",
    "        return np.unpackbits(np.ascontiguousarray((features.to_numpy(dtype=np.uint64) - 1) ^ 0xffffffffffffffff).view(np.uint8), axis=1).astype(np.single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e65a3c3f-e7a9-4c4f-96a6-9f5a53a8f947",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BitboardDrawDataset(Dataset):\n",
    "\n",
    "    @classmethod\n",
    "    def from_dataset_info(cls, dataset_info):\n",
    "        return cls(dataset_info.source_file, dataset_info.chunk_size, dataset_info.shuffle, dataset_info.in_memory)\n",
    "    \n",
    "    def __init__(self, bitboard_file, chunk_size, shuffle = True, in_memory = False):\n",
    "        self.curr_batch = 0\n",
    "        self.shuffle = shuffle\n",
    "        self.bitboard_file = bitboard_file\n",
    "        self.chunk_size = chunk_size\n",
    "        self.datasamples = self.calculate_dataset_size()\n",
    "        \n",
    "        self.batches = ceil(self.datasamples / chunk_size)\n",
    "        self.splits = np.arange(chunk_size, self.datasamples, chunk_size)\n",
    "        self.indices = np.arange(1, self.datasamples+1)\n",
    "        self.splits = np.append(self.splits, [0])\n",
    "\n",
    "        self.in_memory = in_memory or self.chunk_size == self.datasamples\n",
    "        \n",
    "        self.load_data()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.datasamples\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        batch = idx // self.chunk_size\n",
    "        # Laod new data \n",
    "        if self.curr_batch != batch and not self.in_memory:\n",
    "            self.curr_batch = batch\n",
    "            self.load_data()            \n",
    "\n",
    "        idx -= self.chunk_size * self.curr_batch\n",
    "        \n",
    "        return self.bitboards[idx], self.is_draw[idx]\n",
    "\n",
    "    def bitboards_to_layers(self, bitboards):\n",
    "        return np.unpackbits(np.ascontiguousarray(bitboards.to_numpy()).view(np.uint8), axis=1).astype(np.single)\n",
    "\n",
    "    def binary_features_to_layers(self, features):\n",
    "        return np.unpackbits(np.ascontiguousarray((features.to_numpy(dtype=np.uint64) - 1) ^ 0xffffffffffffffff).view(np.uint8), axis=1).astype(np.single)\n",
    "\n",
    "    def load_data(self):\n",
    "        if self.curr_batch == 0 and self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "            \n",
    "        ignore = set(self.indices)\n",
    "\n",
    "        if self.curr_batch == self.batches-1:\n",
    "            ignore.difference_update(self.indices[self.splits[self.curr_batch-1]:])\n",
    "        else:\n",
    "            ignore.difference_update(self.indices[self.splits[self.curr_batch-1]:self.splits[self.curr_batch]])\n",
    "\n",
    "        df = pd.read_csv(self.bitboard_file, sep=\";\", dtype=\"uint64\", usecols=range(18), skiprows=ignore)\n",
    "        self.bitboards = self.bitboards_to_layers(df.iloc[:, range(12)])\n",
    "        # self.meta_features = self.binary_features_to_layers(df[[\"white\", \"cK\", \"cQ\", \"ck\", \"cq\"]])\n",
    "        self.is_draw = df['draw'].to_numpy(dtype=np.single)\n",
    "\n",
    "        # self.bitboards = np.hstack((self.bitboards, self.meta_features))\n",
    "    \n",
    "    def calculate_dataset_size(self):\n",
    "        with open(self.bitboard_file) as f:\n",
    "            return sum(1 for line in f) - 1\n",
    "\n",
    "    def dataloader(self, batch_size):\n",
    "        return DataLoader(self, batch_size=batch_size, shuffle=self.in_memory, pin_memory=True, pin_memory_device=device.type)\n",
    "\n",
    "DatasetInfo = namedtuple(\"DatasetInfo\", [\"source_file\", \"chunk_size\", \"shuffle\", \"in_memory\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4677c52-9176-442b-97dc-b533b2a3edbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, neurons=256):\n",
    "        super().__init__()\n",
    "        self.neurons = neurons\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Unflatten(1, (13, 8, 8)),\n",
    "            nn.Conv2d(13, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Flatten(1),\n",
    "            \n",
    "            nn.Linear(64 * 2 * 2, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(64, 32),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13d423b5aec85db4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T16:43:42.159881Z",
     "start_time": "2024-05-04T16:43:42.156480Z"
    }
   },
   "outputs": [],
   "source": [
    "class DenseNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, layers, sizes, normalization=False):\n",
    "        super().__init__()\n",
    "        self.sizes = sizes\n",
    "        self.layers = layers\n",
    "        ll = []\n",
    "\n",
    "        assert self.layers == len(sizes) - 2, \"Wrong layers to sizes number.\"\n",
    "        \n",
    "        for i in range(layers+1):\n",
    "            ll.append(nn.Linear(self.sizes[i], self.sizes[i+1]))   \n",
    "            if i < layers:\n",
    "                if layers > 1 and normalization:\n",
    "                    ll.append(nn.BatchNorm1d(self.sizes[i+1]))\n",
    "                ll.append(nn.ReLU())\n",
    "                \n",
    "        self.model = nn.Sequential(*ll)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model.forward(x)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Dense_{'_'.join(map(str, self.sizes))}\"\n",
    "\n",
    "    def get_hidden_layer_count(self):\n",
    "        return self.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20cd4926-831f-4d5e-bc3c-dd550104e677",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "87ecc2ce56ba7086",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T19:15:49.831344Z",
     "start_time": "2024-05-04T19:15:49.822055Z"
    }
   },
   "outputs": [],
   "source": [
    "def timeit(f):\n",
    "\n",
    "    def timed(*args, **kw):\n",
    "\n",
    "        ts = time.time()\n",
    "        result = f(*args, **kw)\n",
    "        te = time.time()\n",
    "\n",
    "        print(f\"Took: {te-ts:.2f}s\")\n",
    "        return result\n",
    "    return timed\n",
    "\n",
    "class Train:\n",
    "    \n",
    "    def __init__(self, train_dataset_info, validate_dataset_info, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.train_dataset = BitboardDrawDataset.from_dataset_info(train_dataset_info)\n",
    "        self.validate_dataset = BitboardDrawDataset.from_dataset_info(validate_dataset_info)\n",
    "        self.train_dataloader = self.train_dataset.dataloader(batch_size)\n",
    "        self.validate_dataloader = self.validate_dataset.dataloader(batch_size)\n",
    "\n",
    "        self.loss_fn = nn.BCEWithLogitsLoss()\n",
    "        self.total_batches = len(self.train_dataloader)\n",
    "        self.print_every = 100\n",
    "        self.epoch_print_interval = 1\n",
    "        \n",
    "    def train_one_epoch(self, model, optimizer, p=False) -> int:\n",
    "        running_loss = 0.\n",
    "        last_loss = 0.\n",
    "    \n",
    "        for i, data in enumerate(self.train_dataloader):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.unsqueeze(1).to(device)\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            loss = self.loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            running_loss += loss.item()\n",
    "            if i % self.print_every == self.print_every - 1:\n",
    "                last_loss = running_loss / self.print_every\n",
    "                if p: print(f\"  batch {i+1} loss: {last_loss}\")\n",
    "                running_loss = 0.\n",
    "            elif i == self.total_batches - 1:\n",
    "                last_loss = running_loss / (i % self.print_every + 1)\n",
    "                if p: print(f\"  batch {i+1} loss: {last_loss}\")\n",
    "            \n",
    "        return last_loss\n",
    "    \n",
    "    @timeit\n",
    "    def train(self, model, optimizer, epochs, p=True):\n",
    "        try:\n",
    "            best_vloss = np.inf\n",
    "            best_model = deepcopy(model.state_dict())\n",
    "            best_epoch = 0\n",
    "            best_acc = 0\n",
    "        \n",
    "            for epoch in range(1, epochs + 1):\n",
    "                if p and epoch % self.epoch_print_interval == 0 or epoch == 1: print(f'EPOCH {epoch}')\n",
    "            \n",
    "                # Make sure gradient tracking is on, and do a pass over the data\n",
    "                model.train(True)\n",
    "                avg_loss = self.train_one_epoch(model, optimizer)\n",
    "            \n",
    "                model.eval()\n",
    "    \n",
    "                with torch.no_grad():\n",
    "                    train_acc, train_loss, train_prec, train_recall = self.test(model, self.train_dataloader)\n",
    "                    # train_acc, train_loss, train_prec, train_recall = 0, 0, 0, 0\n",
    "                    validate_acc, validate_loss, validate_prec, validate_recall = self.test(model, self.validate_dataloader)\n",
    "    \n",
    "                    if p and epoch % self.epoch_print_interval == 0 or epoch == 1: \n",
    "                        print(tabulate([[\"Loss\", train_loss, validate_loss], \n",
    "                                        [\"Precision\", train_prec, validate_prec],\n",
    "                                        [\"Recall\", train_recall, validate_recall],\n",
    "                                        [\"Accuracy\", f\"{train_acc:.2f}%\", f\"{validate_acc:.2f}%\"]],\n",
    "                                       headers=[\"\", \"Train\", \"Test\"]))\n",
    "            \n",
    "                if validate_loss < best_vloss:\n",
    "                    best_vloss = validate_loss\n",
    "                    best_model = deepcopy(model.state_dict())\n",
    "                    best_epoch = epoch\n",
    "                    best_acc = validate_acc\n",
    "                    \n",
    "        except KeyboardInterrupt:\n",
    "            self.save_model(model, best_model, best_epoch, lr, momentum, acc)\n",
    "\n",
    "        return best_model, best_epoch, best_acc\n",
    "\n",
    "    def test(self, model, dataloader):\n",
    "        acc, loss = 0, 0\n",
    "        conf_mat = torch.zeros(2, 2) \n",
    "        for i, (vinputs, vlabels) in enumerate(dataloader):\n",
    "            vinputs, vlabels = vinputs.to(device), vlabels.unsqueeze(1).to(device)\n",
    "            voutputs = model(vinputs)\n",
    "            pred = nn.functional.sigmoid(voutputs).round()\n",
    "            \n",
    "            acc += (pred == vlabels).sum() / self.batch_size\n",
    "            loss += self.loss_fn(voutputs, vlabels) \n",
    "            # conf_mat += confusion_matrix(vlabels.to('cpu'), pred.to('cpu'))\n",
    "\n",
    "        acc = acc / (i+1) * 100\n",
    "        loss /= (i+1)\n",
    "\n",
    "        prec = conf_mat[1, 1] / (conf_mat[1, 1] + conf_mat[0, 1])\n",
    "        recall = conf_mat[1, 1] / (conf_mat[1, 1] + conf_mat[1, 0])\n",
    "        \n",
    "        return acc, loss, prec, recall\n",
    "    \n",
    "    \n",
    "                \n",
    "    def save_model(self, model, state_dict, epoch, lr, momentum, acc):\n",
    "        base_path = f\"models/{sizeof_fmt(len(self.train_dataset))}/{str(model.get_hidden_layer_count())}l/\"\n",
    "        if(not os.path.isdir(base_path)):\n",
    "            !mkdir -p {base_path}\n",
    "        \n",
    "        model_path = base_path + f\"{str(model)}_b{self.batch_size}_e{epoch}_lr{lr}_m{momentum}_acc{acc:.2f}\"\n",
    "        torch.save(state_dict, model_path)\n",
    "        \n",
    "    \n",
    "    def find_best(self, model, epochs, lr=1e-3, momentum=0.9):\n",
    "        print(str(model))\n",
    "        model.to(device)\n",
    "        optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "        # optimizer = optim.Adam(model.parameters())\n",
    "        best_model_state_dict, epoch, acc = self.train(model, optimizer, epochs)\n",
    "        self.save_model(model, best_model_state_dict, epoch, lr, momentum, acc)\n",
    "        model.to('cpu')\n",
    "        self.cleanup()\n",
    "        print(\"\")\n",
    "            \n",
    "    def cleanup(self):  \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c98374d5-ed51-4fe6-887d-b1aa7bcf3192",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_info = DatasetInfo(\"data/eval_dataset/bitboards/1000000_0_19_24.csv\", 1000000, False, True)\n",
    "validate_dataset_info = DatasetInfo(\"data/eval_dataset/bitboards/100000_1509579_19_24.csv\", 1000000, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "024a83ff-f64f-45c8-b6f9-e398b6c0a141",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset_info = DatasetInfo(\"data/eval_dataset/bitboards/6882157_0_19_24.csv\", 6882157, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b682679-0fd2-4c68-b410-33f6329a7cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = BitboardDrawDataset.from_dataset_info(eval_dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e9194572-f607-4a49-8c13-36fdeb3713b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Train(eval_dataset_info, validate_dataset_info, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "312630a8-dcbf-4dba-a0b6-e1a33f3e929a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = DenseNetwork(3, [768, 2**14, 2**11, 2**8, 1])\n",
    "model = DenseNetwork(2, [768, 256, 128, 1])\n",
    "# model = DenseNetwork(0, [768, 1])\n",
    "# model.load_state_dict(torch.load(\"models/1M/1l/Dense_768_768_1_b512_e8_lr0.001_m0.9_acc76.14\", map_location=\"cpu\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856c7732-d71f-4bda-af54-277c04f9ed43",
   "metadata": {},
   "source": [
    "## Results of traingin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a68392-35ae-4b7a-97c3-c7cb1dd939df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense_768_256_128_1\n",
      "EPOCH 1\n",
      "           Train               Test\n",
      "---------  ------------------  ------------------\n",
      "Loss       0.6075670719146729  0.6185631155967712\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   67.09%              65.60%\n",
      "EPOCH 2\n",
      "           Train               Test\n",
      "---------  ------------------  -----------------\n",
      "Loss       0.5846351385116577  0.597035825252533\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   69.58%              67.90%\n",
      "EPOCH 3\n",
      "           Train               Test\n",
      "---------  ------------------  ------------------\n",
      "Loss       0.5722998380661011  0.5826573371887207\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   70.60%              69.25%\n",
      "EPOCH 4\n",
      "           Train               Test\n",
      "---------  ------------------  ------------------\n",
      "Loss       0.5601837038993835  0.5678229928016663\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   71.46%              70.46%\n",
      "EPOCH 5\n",
      "           Train               Test\n",
      "---------  ------------------  ------------------\n",
      "Loss       0.5469157099723816  0.5549739599227905\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   72.42%              71.47%\n",
      "EPOCH 6\n",
      "           Train              Test\n",
      "---------  -----------------  ------------------\n",
      "Loss       0.545362651348114  0.5507650971412659\n",
      "Precision  nan                nan\n",
      "Recall     nan                nan\n",
      "Accuracy   72.33%             71.65%\n",
      "EPOCH 7\n",
      "           Train             Test\n",
      "---------  ----------------  ------------------\n",
      "Loss       0.53505939245224  0.5427213907241821\n",
      "Precision  nan               nan\n",
      "Recall     nan               nan\n",
      "Accuracy   72.96%            72.11%\n",
      "EPOCH 8\n",
      "           Train               Test\n",
      "---------  ------------------  ------------------\n",
      "Loss       0.5229083895683289  0.5262803435325623\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   74.06%              73.66%\n",
      "EPOCH 9\n",
      "           Train               Test\n",
      "---------  ------------------  ------------------\n",
      "Loss       0.5126306414604187  0.5187609195709229\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   74.76%              74.11%\n",
      "EPOCH 10\n",
      "           Train               Test\n",
      "---------  ------------------  ------------------\n",
      "Loss       0.5112512111663818  0.5157787203788757\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   74.59%              73.93%\n",
      "EPOCH 11\n",
      "           Train                Test\n",
      "---------  -------------------  ------------------\n",
      "Loss       0.49701839685440063  0.5006983280181885\n",
      "Precision  nan                  nan\n",
      "Recall     nan                  nan\n",
      "Accuracy   75.67%               75.17%\n",
      "EPOCH 12\n"
     ]
    }
   ],
   "source": [
    "pipe.find_best(model, 50, lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b28464852583617f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T20:32:27.823212Z",
     "start_time": "2024-05-04T19:15:51.913062Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense_768_768_256_128_1\n",
      "EPOCH 1\n",
      "           Train             Test\n",
      "---------  ----------------  ------------------\n",
      "Loss       0.60765540599823  0.6169381141662598\n",
      "Precision  nan               nan\n",
      "Recall     nan               nan\n",
      "Accuracy   67.23%            65.68%\n",
      "EPOCH 2\n",
      "           Train               Test\n",
      "---------  ------------------  ------------------\n",
      "Loss       0.5770673751831055  0.5866464376449585\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   70.33%              69.13%\n",
      "EPOCH 3\n",
      "           Train               Test\n",
      "---------  ------------------  ------------------\n",
      "Loss       0.5648491978645325  0.5703172087669373\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   71.15%              70.52%\n",
      "EPOCH 4\n",
      "           Train               Test\n",
      "---------  ------------------  ------------------\n",
      "Loss       0.5420290231704712  0.5499448776245117\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   72.74%              71.69%\n",
      "EPOCH 5\n",
      "           Train               Test\n",
      "---------  ------------------  ------------------\n",
      "Loss       0.5436191558837891  0.5481529235839844\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   72.69%              72.19%\n",
      "EPOCH 6\n",
      "           Train               Test\n",
      "---------  ------------------  ------------------\n",
      "Loss       0.5568835139274597  0.5630940198898315\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   70.49%              69.72%\n",
      "EPOCH 7\n",
      "           Train               Test\n",
      "---------  ------------------  ------------------\n",
      "Loss       0.5007023215293884  0.5048590302467346\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   75.71%              75.29%\n",
      "EPOCH 8\n",
      "           Train                Test\n",
      "---------  -------------------  -------------------\n",
      "Loss       0.47868531942367554  0.47971928119659424\n",
      "Precision  nan                  nan\n",
      "Recall     nan                  nan\n",
      "Accuracy   77.01%               76.67%\n",
      "EPOCH 9\n",
      "           Train                Test\n",
      "---------  -------------------  ------------------\n",
      "Loss       0.47688865661621094  0.4784945845603943\n",
      "Precision  nan                  nan\n",
      "Recall     nan                  nan\n",
      "Accuracy   76.60%               76.30%\n",
      "EPOCH 10\n",
      "           Train                Test\n",
      "---------  -------------------  ------------------\n",
      "Loss       0.45326942205429077  0.4554938077926636\n",
      "Precision  nan                  nan\n",
      "Recall     nan                  nan\n",
      "Accuracy   78.67%               78.37%\n",
      "EPOCH 11\n",
      "           Train                Test\n",
      "---------  -------------------  ------------------\n",
      "Loss       0.43618708848953247  0.4364281892776489\n",
      "Precision  nan                  nan\n",
      "Recall     nan                  nan\n",
      "Accuracy   79.62%               79.36%\n",
      "EPOCH 12\n",
      "           Train                Test\n",
      "---------  -------------------  -----------------\n",
      "Loss       0.41928189992904663  0.421350359916687\n",
      "Precision  nan                  nan\n",
      "Recall     nan                  nan\n",
      "Accuracy   80.50%               80.25%\n",
      "EPOCH 13\n",
      "           Train               Test\n",
      "---------  ------------------  ------------------\n",
      "Loss       0.4123820662498474  0.4113311767578125\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   80.93%              80.81%\n",
      "EPOCH 14\n",
      "           Train               Test\n",
      "---------  ------------------  -------------------\n",
      "Loss       0.4091227948665619  0.41061705350875854\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   81.00%              80.68%\n",
      "EPOCH 15\n",
      "           Train               Test\n",
      "---------  ------------------  -------------------\n",
      "Loss       0.3903857469558716  0.38876667618751526\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   81.97%              81.84%\n",
      "EPOCH 16\n",
      "           Train               Test\n",
      "---------  ------------------  ------------------\n",
      "Loss       0.3897532820701599  0.3895343244075775\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   82.13%              81.88%\n",
      "EPOCH 17\n",
      "           Train                Test\n",
      "---------  -------------------  ------------------\n",
      "Loss       0.36444970965385437  0.3646678328514099\n",
      "Precision  nan                  nan\n",
      "Recall     nan                  nan\n",
      "Accuracy   83.48%               83.23%\n",
      "EPOCH 18\n",
      "           Train               Test\n",
      "---------  ------------------  -------------------\n",
      "Loss       0.3635002076625824  0.35821548104286194\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   83.23%              83.25%\n",
      "EPOCH 19\n",
      "           Train               Test\n",
      "---------  ------------------  -------------------\n",
      "Loss       0.3454296290874481  0.34501880407333374\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   84.36%              84.16%\n",
      "EPOCH 20\n",
      "           Train               Test\n",
      "---------  ------------------  ------------------\n",
      "Loss       0.3426302969455719  0.3428818881511688\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   84.39%              84.06%\n",
      "EPOCH 21\n",
      "           Train                Test\n",
      "---------  -------------------  -------------------\n",
      "Loss       0.33545252680778503  0.33343860507011414\n",
      "Precision  nan                  nan\n",
      "Recall     nan                  nan\n",
      "Accuracy   84.88%               84.83%\n",
      "EPOCH 22\n",
      "           Train                Test\n",
      "---------  -------------------  ------------------\n",
      "Loss       0.31919971108436584  0.3212621510028839\n",
      "Precision  nan                  nan\n",
      "Recall     nan                  nan\n",
      "Accuracy   85.71%               85.33%\n",
      "EPOCH 23\n",
      "           Train               Test\n",
      "---------  ------------------  ------------------\n",
      "Loss       0.3126629889011383  0.3116900622844696\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   86.11%              85.96%\n",
      "EPOCH 24\n",
      "           Train               Test\n",
      "---------  ------------------  -------------------\n",
      "Loss       0.3026760220527649  0.30275535583496094\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   86.50%              86.25%\n",
      "EPOCH 25\n",
      "           Train                Test\n",
      "---------  -------------------  ------------------\n",
      "Loss       0.29674771428108215  0.2951497733592987\n",
      "Precision  nan                  nan\n",
      "Recall     nan                  nan\n",
      "Accuracy   86.80%               86.70%\n",
      "EPOCH 26\n",
      "           Train               Test\n",
      "---------  ------------------  ------------------\n",
      "Loss       0.2851320505142212  0.2847612798213959\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   87.49%              87.38%\n",
      "EPOCH 27\n",
      "           Train                Test\n",
      "---------  -------------------  ------------------\n",
      "Loss       0.28370317816734314  0.2817804217338562\n",
      "Precision  nan                  nan\n",
      "Recall     nan                  nan\n",
      "Accuracy   87.44%               87.31%\n",
      "EPOCH 28\n",
      "           Train                Test\n",
      "---------  -------------------  -------------------\n",
      "Loss       0.27406811714172363  0.27514785528182983\n",
      "Precision  nan                  nan\n",
      "Recall     nan                  nan\n",
      "Accuracy   87.89%               87.63%\n",
      "EPOCH 29\n",
      "           Train               Test\n",
      "---------  ------------------  ------------------\n",
      "Loss       0.2791258990764618  0.2812235653400421\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   87.46%              87.11%\n",
      "EPOCH 30\n",
      "           Train              Test\n",
      "---------  -----------------  -------------------\n",
      "Loss       0.265708863735199  0.26450008153915405\n",
      "Precision  nan                nan\n",
      "Recall     nan                nan\n",
      "Accuracy   88.34%             88.09%\n",
      "EPOCH 31\n",
      "           Train                Test\n",
      "---------  -------------------  ------------------\n",
      "Loss       0.27230915427207947  0.2805846929550171\n",
      "Precision  nan                  nan\n",
      "Recall     nan                  nan\n",
      "Accuracy   87.91%               87.34%\n",
      "EPOCH 32\n",
      "           Train               Test\n",
      "---------  ------------------  ------------------\n",
      "Loss       0.2528788149356842  0.2524830400943756\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   88.93%              88.65%\n",
      "EPOCH 33\n",
      "           Train               Test\n",
      "---------  ------------------  -------------------\n",
      "Loss       0.2563575804233551  0.26081427931785583\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   88.65%              88.18%\n",
      "EPOCH 34\n",
      "           Train                Test\n",
      "---------  -------------------  -------------------\n",
      "Loss       0.24717578291893005  0.24502108991146088\n",
      "Precision  nan                  nan\n",
      "Recall     nan                  nan\n",
      "Accuracy   89.14%               89.02%\n",
      "EPOCH 35\n",
      "           Train                Test\n",
      "---------  -------------------  ------------------\n",
      "Loss       0.24361050128936768  0.2413882613182068\n",
      "Precision  nan                  nan\n",
      "Recall     nan                  nan\n",
      "Accuracy   89.22%               89.11%\n",
      "EPOCH 36\n",
      "           Train                Test\n",
      "---------  -------------------  -------------------\n",
      "Loss       0.23559100925922394  0.23527224361896515\n",
      "Precision  nan                  nan\n",
      "Recall     nan                  nan\n",
      "Accuracy   89.73%               89.49%\n",
      "EPOCH 37\n",
      "           Train                Test\n",
      "---------  -------------------  ------------------\n",
      "Loss       0.23388899862766266  0.2348487228155136\n",
      "Precision  nan                  nan\n",
      "Recall     nan                  nan\n",
      "Accuracy   89.75%               89.43%\n",
      "EPOCH 38\n",
      "           Train               Test\n",
      "---------  ------------------  -------------------\n",
      "Loss       0.2312302589416504  0.23407231271266937\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   89.90%              89.42%\n",
      "EPOCH 39\n",
      "           Train                Test\n",
      "---------  -------------------  ------------------\n",
      "Loss       0.21874041855335236  0.2136123776435852\n",
      "Precision  nan                  nan\n",
      "Recall     nan                  nan\n",
      "Accuracy   90.43%               90.52%\n",
      "EPOCH 40\n",
      "           Train               Test\n",
      "---------  ------------------  ------------------\n",
      "Loss       0.2416549175977707  0.2392057180404663\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   89.12%              89.02%\n",
      "EPOCH 41\n",
      "           Train                Test\n",
      "---------  -------------------  -------------------\n",
      "Loss       0.21676389873027802  0.21229025721549988\n",
      "Precision  nan                  nan\n",
      "Recall     nan                  nan\n",
      "Accuracy   90.54%               90.56%\n",
      "EPOCH 42\n",
      "           Train               Test\n",
      "---------  ------------------  -------------------\n",
      "Loss       0.2078133523464203  0.20439352095127106\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   90.99%              90.92%\n",
      "EPOCH 43\n",
      "           Train                Test\n",
      "---------  -------------------  -------------------\n",
      "Loss       0.20837244391441345  0.20448413491249084\n",
      "Precision  nan                  nan\n",
      "Recall     nan                  nan\n",
      "Accuracy   90.94%               90.87%\n",
      "EPOCH 44\n",
      "           Train                Test\n",
      "---------  -------------------  -------------------\n",
      "Loss       0.19770127534866333  0.19211184978485107\n",
      "Precision  nan                  nan\n",
      "Recall     nan                  nan\n",
      "Accuracy   91.50%               91.57%\n",
      "EPOCH 45\n",
      "           Train                Test\n",
      "---------  -------------------  -------------------\n",
      "Loss       0.19562146067619324  0.19316256046295166\n",
      "Precision  nan                  nan\n",
      "Recall     nan                  nan\n",
      "Accuracy   91.56%               91.52%\n",
      "EPOCH 46\n",
      "           Train                Test\n",
      "---------  -------------------  -------------------\n",
      "Loss       0.19483253359794617  0.19061249494552612\n",
      "Precision  nan                  nan\n",
      "Recall     nan                  nan\n",
      "Accuracy   91.58%               91.51%\n",
      "EPOCH 47\n",
      "           Train               Test\n",
      "---------  ------------------  -------------------\n",
      "Loss       0.1899651736021042  0.18547607958316803\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   91.81%              91.78%\n",
      "EPOCH 48\n",
      "           Train                Test\n",
      "---------  -------------------  ------------------\n",
      "Loss       0.24324268102645874  0.2504378855228424\n",
      "Precision  nan                  nan\n",
      "Recall     nan                  nan\n",
      "Accuracy   89.06%               88.64%\n",
      "EPOCH 49\n",
      "           Train                Test\n",
      "---------  -------------------  -------------------\n",
      "Loss       0.19250567257404327  0.18507514894008636\n",
      "Precision  nan                  nan\n",
      "Recall     nan                  nan\n",
      "Accuracy   91.69%               91.75%\n",
      "EPOCH 50\n",
      "           Train                Test\n",
      "---------  -------------------  -------------------\n",
      "Loss       0.19079792499542236  0.18763579428195953\n",
      "Precision  nan                  nan\n",
      "Recall     nan                  nan\n",
      "Accuracy   91.71%               91.66%\n",
      "Took: 671.93s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe.find_best(model, 50, lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d9126a4-6bfb-4bb3-b850-3235a42e6b56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense_768_768_1\n",
      "EPOCH 1\n",
      "           Train               Test\n",
      "---------  ------------------  ------------------\n",
      "Loss       0.5491299629211426  0.4815320372581482\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   72.51%              76.71%\n",
      "EPOCH 2\n",
      "           Train               Test\n",
      "---------  ------------------  ----------------\n",
      "Loss       0.5368010997772217  0.48187255859375\n",
      "Precision  nan                 nan\n",
      "Recall     nan                 nan\n",
      "Accuracy   73.27%              76.64%\n",
      "EPOCH 3\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'lr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 72\u001b[0m, in \u001b[0;36mTrain.train\u001b[0;34m(self, model, optimizer, epochs, p)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 72\u001b[0m     train_acc, train_loss, train_prec, train_recall \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;66;03m# train_acc, train_loss, train_prec, train_recall = 0, 0, 0, 0\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[21], line 99\u001b[0m, in \u001b[0;36mTrain.test\u001b[0;34m(self, model, dataloader)\u001b[0m\n\u001b[1;32m     98\u001b[0m vinputs, vlabels \u001b[38;5;241m=\u001b[39m vinputs\u001b[38;5;241m.\u001b[39mto(device), vlabels\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 99\u001b[0m voutputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvinputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m pred \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39msigmoid(voutputs)\u001b[38;5;241m.\u001b[39mround()\n",
      "File \u001b[0;32m~/venvs/nn-snake/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/nn-snake/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[9], line 21\u001b[0m, in \u001b[0;36mDenseNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/nn-snake/lib/python3.12/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/venvs/nn-snake/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/nn-snake/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/venvs/nn-snake/lib/python3.12/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_best_neuron\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 126\u001b[0m, in \u001b[0;36mTrain.find_best_neuron\u001b[0;34m(self, model, epochs, lr, momentum)\u001b[0m\n\u001b[1;32m    124\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlr, momentum\u001b[38;5;241m=\u001b[39mmomentum)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# optimizer = optim.Adam(model.parameters())\u001b[39;00m\n\u001b[0;32m--> 126\u001b[0m best_model_state_dict, epoch, acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_model(model, best_model_state_dict, epoch, lr, momentum, acc)\n\u001b[1;32m    128\u001b[0m model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[21], line 6\u001b[0m, in \u001b[0;36mtimeit.<locals>.timed\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtimed\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m      5\u001b[0m     ts \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 6\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     te \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTook: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mte\u001b[38;5;241m-\u001b[39mts\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[21], line 90\u001b[0m, in \u001b[0;36mTrain.train\u001b[0;34m(self, model, optimizer, epochs, p)\u001b[0m\n\u001b[1;32m     87\u001b[0m             best_acc \u001b[38;5;241m=\u001b[39m validate_acc\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m---> 90\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_model(model, best_model, best_epoch, \u001b[43mlr\u001b[49m, momentum, acc)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_model, best_epoch, best_acc\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lr' is not defined"
     ]
    }
   ],
   "source": [
    "pipe.find_best(model, 50, lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcb51abc-7c85-47e2-9397-2a6982466a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All weights and biases have been saved to the 'models/weights/1l/83/' directory.\n"
     ]
    }
   ],
   "source": [
    "def save_weights_to_csv(model: nn.Module, directory: str):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        layer_name, param_type = name.rsplit('.', 1)\n",
    "        param_data = param.detach().cpu().numpy()\n",
    "        df = pd.DataFrame(param_data)\n",
    "        filename = f\"{layer_name}_{param_type}.csv\"\n",
    "        df.to_csv(os.path.join(directory, filename), index=False)\n",
    "\n",
    "    print(f\"All weights and biases have been saved to the '{directory}' directory.\")\n",
    "\n",
    "save_weights_to_csv(model, 'models/weights/1l/83/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "515b8b65-6b91-420d-963a-b8c7ea57a071",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_to_bits(dataset):\n",
    "    dataset.map(lambda x: \";\".join(np.char.mod('%d', np.unpackbits(np.array([x]).view(np.uint8))))).to_csv(\"dataset_bits.csv\", sep=\";\", index=False)\n",
    "    bity = pd.read_csv(\"dataset_bits.csv\", dtype=\"uint64\", sep=\";\", header=None)\n",
    "    dataset.rename(columns={\"draw\": 768})\n",
    "    pd.concat([bity, dataset.rename(columns={\"draw\": 768})], axis=1).to_csv(\"dataset_bits.csv\", sep=\";\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
